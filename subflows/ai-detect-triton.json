[{"id":"5631ce2401554b93","type":"subflow","name":"[AI] Detect - Triton","info":"Send image to NVIDIA Triton Inference server using HTTP API.\n\nModel should be configured and loaded to server before using.\n\nThis node has been tested and developed with MobileNetV2 based object detection model.\n\nSupported Tequ-models:\n - tequ-fish-species-detection\n - ssd-example-model\n","category":"Tequ-API Client","in":[{"x":80,"y":140,"wires":[{"id":"6acd03850a731b8a"}]}],"out":[{"x":1120,"y":300,"wires":[{"id":"e21f34110778e310","port":1},{"id":"82f22fd2660e14f2","port":0}]},{"x":1120,"y":460,"wires":[{"id":"2cd47cbd972c88b5","port":0}]},{"x":340,"y":540,"wires":[{"id":"75ad742de2c2f110","port":0}]},{"x":520,"y":340,"wires":[{"id":"e437a27db3c2e6f3","port":0}]}],"env":[{"name":"threshold","type":"num","value":"0.75","ui":{"type":"spinner","opts":{"min":0,"max":1}}},{"name":"model_name","type":"str","value":"ssd-example-model","ui":{"type":"input","opts":{"types":["str","env"]}}},{"name":"triton_server_url","type":"str","value":"tequ-jetson-nx-1:8000","ui":{"type":"input","opts":{"types":["str"]}}},{"name":"image_width_cm","type":"env","value":"image_width_cm","ui":{"type":"input","opts":{"types":["json","env"]}}},{"name":"gzip_response","type":"bool","value":"false"}],"meta":{"module":"node-red-contrib-tequ-ai-triton","version":"0.0.1","author":"juha.autioniemi@lapinamk.fi","desc":"Inference image using NVIDIA Triton Inference server.","license":"MIT"},"color":"#FFCC66","inputLabels":["Image buffer in"],"outputLabels":["Inference result","Model configuration","Is server ready?","Preprocess output"],"icon":"node-red/status.svg","status":{"x":1120,"y":640,"wires":[{"id":"4d14015f6c2d859b","port":0}]}},{"id":"e437a27db3c2e6f3","type":"function","z":"5631ce2401554b93","name":"Pre-process","func":"const imageBuffer = msg.payload;\nconst modelName = env.get(\"model_name\")\nconst server_url = env.get(\"triton_server_url\")\n\n\nasync function createImageTensor(input){\n    return tf.tidy(() => {\n        const tensor = tf.node.decodeJpeg(input, 3).expandDims(0);\n        const shape = tensor.shape;\n        return {\"tensor\":tensor,\"shape\":shape}\n    });\n}\n\nconst image_tensor = await createImageTensor(imageBuffer)\nconst image_tensor_buffer = Buffer.from(image_tensor[\"tensor\"].dataSync());\nconst image_tensor_buffer_length = image_tensor_buffer.length;\nimage_tensor[\"tensor\"].dispose()\n\nlet inference_header = {\n      \"model_name\" : \"test\",\n      \"inputs\" : [\n        {\n          \"name\" : \"input_tensor\",\n          \"shape\" : image_tensor[\"shape\"],\n          \"datatype\" : \"UINT8\",\n          \"parameters\" : {\n              \"binary_data_size\":image_tensor_buffer_length\n          }\n        }\n      ],\n      \"outputs\" : [\n        {\n          \"name\" : \"detection_scores\",\n          \"parameters\" : {\n            \"binary_data\" : false\n          }\n        },\n         {\n          \"name\" : \"detection_boxes\",\n          \"parameters\" : {\n            \"binary_data\" : false\n          }\n        },\n         {\n          \"name\" : \"detection_classes\",\n          \"parameters\" : {\n            \"binary_data\" : false\n          }\n        }\n      ]\n    }\n\nlet inference_header_buffer = Buffer.from(JSON.stringify(inference_header))\nlet inference_header_length = inference_header_buffer.length\n\nmsg.method = \"POST\";\nmsg.payload = Buffer.concat([inference_header_buffer,image_tensor_buffer])\nmsg.url = server_url+\"/v2/models/\"+modelName+\"/infer\";\nmsg.headers = {\n    \"Content-Type\":\"application/octet-stream\",\n    \"Inference-Header-Content-Length\":inference_header_length,\n    \"Content-Length\":inference_header_length+image_tensor_buffer_length\n};\n    \nif(env.get(\"gzip_response\")){\n    msg.headers[\"Accept-Encoding\"] = \"gzip\"\n} \n    \n    \npre_process_time =  Date.now()  - msg.start;\nmsg.pre_process_time = pre_process_time;\nnode.status({fill:\"green\",shape:\"dot\",text:pre_process_time+\" ms\"});    \nreturn msg;","outputs":1,"noerr":0,"initialize":"","finalize":"// Code added here will be run when the\n// node is being stopped or re-deployed.\nnode.status({fill:\"blue\",shape:\"dot\",text:\"Stopping node...\"});  \ncontext.set(\"model\",undefined)\ntf.disposeVariables()","libs":[{"var":"fs","module":"fs"},{"var":"os","module":"os"},{"var":"zlib","module":"zlib"},{"var":"tf","module":"@tensorflow/tfjs-node-gpu"}],"x":210,"y":280,"wires":[["ae732480740057bb"]]},{"id":"ae732480740057bb","type":"http request","z":"5631ce2401554b93","name":"","method":"use","ret":"bin","paytoqs":"ignore","url":"","tls":"","persist":true,"proxy":"","authType":"","senderr":false,"x":570,"y":280,"wires":[["e21f34110778e310"]]},{"id":"ec118ac07d12786c","type":"function","z":"5631ce2401554b93","name":"Set threshold & image_width_cm","func":"//Define threshold\nlet threshold = 0;\nconst global_settings = global.get(\"settings\") || undefined\nlet thresholdType = \"\"\n\nif(global_settings !== undefined){\n    if(\"threshold\" in global_settings){\n        threshold = global_settings[\"threshold\"]\n        thresholdType = \"global\";\n    }\n}\n\nelse if(\"threshold\" in msg){\n    threshold = msg.threshold;\n    thresholdType = \"msg\";\n    if(threshold < 0){\n        threshold = 0\n    }\n    else if(threshold > 1){\n        threshold = 1\n    }\n}\n\nelse{\n    try{\n        threshold = env.get(\"threshold\");\n        thresholdType = \"env\";\n    }\n    catch(err){\n        threshold = 0.5\n        thresholdType = \"default\";\n    }\n}\n\n\ntry{\n    image_width_cm_type = \"env\";\n    image_width_cm = JSON.parse(env.get(\"image_width_cm\"))[msg.topic];\n        \n}\ncatch(err){\n    image_width_cm = 130\n    image_width_cm_type = \"default\";\n}\n\nif(image_width_cm == undefined){\n    image_width_cm = 130\n}\n\n\nif(threshold == undefined){\n    threshold = 0\n}\n\nmsg.thresholdType = thresholdType;\nmsg.threshold = threshold;\nmsg.image_width_cm = image_width_cm;\nmsg.image_width_cm_type = image_width_cm_type;\n//node.status({fill:\"green\",shape:\"dot\",text:\"threshold: \"+threshold+\" | Image width: \"+image_width_cm});\nreturn msg;","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[],"x":980,"y":200,"wires":[["e437a27db3c2e6f3"]]},{"id":"03ab9d1c47664217","type":"function","z":"5631ce2401554b93","name":"isBuffer?","func":"let timestamp = new Date().toISOString();\nmsg.start = Date.now()\n\nif(Buffer.isBuffer(msg.payload)){\n    node.status({fill:\"green\",shape:\"dot\",text:timestamp + \" OK\"});  \n    msg.image = msg.payload;\n    return msg;\n}\nelse{\n    node.error(\"msg.payload is not an image buffer\",msg)\n    node.status({fill:\"red\",shape:\"dot\",text:timestamp + \" msg.payload is not an image buffer\"});  \n    return null;\n}","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[],"x":200,"y":200,"wires":[["b9b96fd3ec8d1f16"]]},{"id":"3d1c02bbb34b94d2","type":"exif","z":"5631ce2401554b93","name":"","mode":"normal","property":"payload","x":750,"y":200,"wires":[["ec118ac07d12786c"]]},{"id":"ba5c74dbbf34ce81","type":"image-info","z":"5631ce2401554b93","name":"","x":570,"y":200,"wires":[["3d1c02bbb34b94d2"]]},{"id":"b9b96fd3ec8d1f16","type":"moment","z":"5631ce2401554b93","name":"ts","topic":"","input":"","inputType":"date","inTz":"Europe/Helsinki","adjAmount":0,"adjType":"days","adjDir":"add","format":"HH:mm:ss.SSS","locale":"fi-FI","output":"ts","outputType":"msg","outTz":"Europe/Helsinki","x":390,"y":200,"wires":[["ba5c74dbbf34ce81"]]},{"id":"43f5be17dfdf191a","type":"http request","z":"5631ce2401554b93","name":"http request","method":"use","ret":"obj","paytoqs":"ignore","url":"","tls":"","persist":false,"proxy":"","authType":"","senderr":false,"x":690,"y":460,"wires":[["2cd47cbd972c88b5"]]},{"id":"a772b501dd1a1790","type":"function","z":"5631ce2401554b93","name":"request","func":"let modelName = env.get(\"model_name\")\nlet server_url = env.get(\"triton_server_url\")\n\nmsg.requestTimeout = 1000;\nmsg.method = \"GET\";\nmsg.url = server_url+\"/v2/models/\"+modelName+\"/config\";\nreturn msg;","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[],"x":520,"y":460,"wires":[["43f5be17dfdf191a"]]},{"id":"2cd47cbd972c88b5","type":"function","z":"5631ce2401554b93","name":"status","func":"let statusCode = msg.statusCode;\n\nif(statusCode == 200){\n    let model_data = msg.payload;\n    let modelName = env.get(\"model_name\")\n    parsed_value = JSON.parse(model_data.parameters.metadata.string_value)\n    model_data.parameters.labels = parsed_value.labels\n    model_data.parameters.metadata = parsed_value.metadata\n    flow.set(modelName,model_data)  \n    node.status({fill:\"green\",shape:\"dot\",text:\" Model configuration loaded.\"});   \n    flow.set(\"ready\",true)\n    return msg\n}\nelse{\n    flow.set(\"ready\",false)\n    node.status({fill:\"red\",shape:\"dot\",text:msg.statusCode+\": \"+\"Server is not ready.\"});   \n    //node.error(msg.statusCode,msg.payload)\n    return null\n}\n\nreturn msg;","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[],"x":850,"y":460,"wires":[[]]},{"id":"4d14015f6c2d859b","type":"status","z":"5631ce2401554b93","name":"","scope":["2cd47cbd972c88b5","82f22fd2660e14f2","e21f34110778e310"],"x":840,"y":640,"wires":[[]]},{"id":"75ad742de2c2f110","type":"inject","z":"5631ce2401554b93","name":"","props":[{"p":"payload"},{"p":"topic","vt":"str"}],"repeat":"5","crontab":"","once":true,"onceDelay":"1","topic":"","payload":"ready","payloadType":"flow","x":210,"y":460,"wires":[["a1fd043ae35c0f38"]]},{"id":"a1fd043ae35c0f38","type":"switch","z":"5631ce2401554b93","name":"ready?","property":"payload","propertyType":"msg","rules":[{"t":"false"}],"checkall":"false","repair":false,"outputs":1,"x":370,"y":460,"wires":[["a772b501dd1a1790"]]},{"id":"28a1d033c2b13ffd","type":"catch","z":"5631ce2401554b93","name":"","scope":["43f5be17dfdf191a"],"uncaught":false,"x":530,"y":560,"wires":[["2c0f090b765324e0"]]},{"id":"2c0f090b765324e0","type":"function","z":"5631ce2401554b93","name":"","func":" node.status({fill:\"red\",shape:\"dot\",text:\"Server is not ready.\"});  \n","outputs":0,"noerr":0,"initialize":"","finalize":"","libs":[],"x":680,"y":560,"wires":[]},{"id":"ea326102a82422d5","type":"inject","z":"5631ce2401554b93","name":"","props":[{"p":"payload"},{"p":"topic","vt":"str"}],"repeat":"","crontab":"","once":true,"onceDelay":0.1,"topic":"","payload":"","payloadType":"date","x":210,"y":380,"wires":[["7d0d5bef2ee0f025"]]},{"id":"7d0d5bef2ee0f025","type":"change","z":"5631ce2401554b93","name":"","rules":[{"t":"set","p":"ready","pt":"flow","to":"false","tot":"bool"}],"action":"","property":"","from":"","to":"","reg":false,"x":390,"y":380,"wires":[[]]},{"id":"82f22fd2660e14f2","type":"function","z":"5631ce2401554b93","name":"Post-process","func":"let start_post_process = Date.now()\nlet inference_result = msg.payload;\nlet results = [];\nconst modelName = env.get(\"model_name\")\nconst model = flow.get(modelName);\nconst labels = model.parameters.labels;\nconst metadata = model.parameters.metadata;\nconst ts = msg.ts;\n\nconst threshold = msg.threshold;\nconst image_width = msg.width;\nconst image_height = msg.height;\nconst originalImage = msg.image;\nlet scores;\nlet boxes;\nlet names;\n\nfunction chunk(arr, chunkSize) {\n  if (chunkSize <= 0) throw \"Invalid chunk size\";\n  var R = [];\n  for (var i=0,len=arr.length; i<len; i+=chunkSize)\n    R.push(arr.slice(i,i+chunkSize));\n  return R;\n}\n\nfor(let i=0;i<(inference_result.outputs).length;i++){\n    //node.warn(inference_result.outputs[i])\n    \n    if(inference_result.outputs[i][\"name\"] == \"detection_scores\"){\n        scores = inference_result.outputs[i].data\n    }\n    else if(inference_result.outputs[i][\"name\"] == \"detection_boxes\"){\n        boxes = inference_result.outputs[i].data\n        boxes = chunk(boxes,4)\n        \n    }\n    else if(inference_result.outputs[i][\"name\"] == \"detection_classes\"){\n        names = inference_result.outputs[i].data \n    }\n} \n\nfor (let i = 0; i < scores.length; i++) {\n    if (scores[i] > threshold) {\n        newObject = {\n            \"bbox\":[\n                    boxes[i][1] * image_width,\n                    boxes[i][0] * image_height,\n                    (boxes[i][3] - boxes[i][1]) * image_width,\n                    (boxes[i][2] - boxes[i][0]) * image_height\n            ],\n            \"class\":labels[names[i]-1],\n            \"label\":labels[names[i]-1],\n            \"score\":scores[i],\n            \"length_cm\":NaN\n            }\n        results.push(newObject)\n    }\n}\n        \n//Calculate object width if image_width_cm is given input message\n if(\"image_width_cm\" in msg){\n    const image_width_cm = msg.image_width_cm;    \n    for(let j=0;j<results.length;j++){\n        px_in_cm = image_width_cm / msg.width\n        object_size_cm = px_in_cm * results[j].bbox[2]\n        results[j].length_cm = Math.round(object_size_cm)\n    }\n}\n        \n   \n        \n// Create output message\nlet result_message = {\n    \"labels\":labels,\n    \"thresholdType\":msg.thresholdType,\n    \"threshold\": msg.threshold,\n    \"image_width_cm\":msg.image_width_cm,\n    \"image_width_cm_type\":msg.image_width_cm_type,\n    \"topic\":msg.topic,\n    \"payload\":{\n        \"inference\":{\n            \"metadata\":metadata,\n            \"time_ms\": 0,\n            \"validated\":false,\n            \"result\":results,\n            \"type\":\"object detection\"\n        },\n        \"image\":{\n            \"buffer\":originalImage,\n            \"width\": msg.width,\n            \"height\": msg.height,\n            \"type\": msg.type,\n            \"size\": (originalImage).length,\n            \"exif\":{}\n            }\n    }\n}\n\n// Add exif information\nif(msg.exif){\n    result_message.payload.image.exif = msg.exif\n}\n\nresult_message.tf = msg.tf;\npost_process_time = Date.now()  - start_post_process;       \ntotal_ms =  Date.now()  - msg.start;   \n\nresult_message.payload.inference.time_ms = msg.request_time\n        \nnode.status({fill:\"blue\",shape:\"dot\",text: msg.pre_process_time+\" ms | \" +msg.request_time+ \" ms | \" +post_process_time+ \" ms | \"+total_ms+\" ms\"});           \n    \nreturn result_message;","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[],"x":930,"y":260,"wires":[[]]},{"id":"e21f34110778e310","type":"function","z":"5631ce2401554b93","name":"Status","func":"let statusCode = msg.statusCode;\n\nif(statusCode == 200){\n    if(env.get(\"gzip_response\")){\n        msg.payload = JSON.parse(zlib.gunzipSync(msg.payload))\n    }   \n    else{\n        msg.payload = JSON.parse(msg.payload)  \n    }\n    \n    request_time =  (Date.now() - msg.start) - msg.pre_process_time;\n    msg.request_time = request_time\n    \n    return [msg,null]\n}\nelse{\n    node.status({fill:\"yellow\",shape:\"dot\",text:\"Request failed... checking server...\"});  \n    flow.set(\"ready\",false)\n    return [null,msg]\n}","outputs":2,"noerr":0,"initialize":"","finalize":"","libs":[{"var":"zlib","module":"zlib"}],"x":750,"y":280,"wires":[["82f22fd2660e14f2"],[]]},{"id":"6acd03850a731b8a","type":"switch","z":"5631ce2401554b93","name":"ready?","property":"ready","propertyType":"flow","rules":[{"t":"true"}],"checkall":"false","repair":false,"outputs":1,"x":190,"y":140,"wires":[["03ab9d1c47664217"]]},{"id":"38d2b24b340468a3","type":"subflow:5631ce2401554b93","z":"69a682b883d90b2f","name":"","env":[{"name":"model_name","value":"tequ-fish-species-detection","type":"str"},{"name":"triton_server_url","value":"192.168.86.81:8000","type":"str"},{"name":"gzip_response","value":"true","type":"bool"}],"x":670,"y":240,"wires":[["1710963724edbae5","783673c440d0f05b"],["1cdadb049d8bb4b9"],["f59494c2d44352d3"],["1d756142954ed411"]]}]
