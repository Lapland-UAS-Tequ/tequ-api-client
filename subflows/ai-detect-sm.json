[{"id":"1261d76017c1af2f","type":"subflow","name":"[AI] Detect-sm","info":"Make prediction on image with Tensorflow saved model trained with tequ-tf2-ca-training-pipeline.\n\nInput image must be image buffer in **'msg.payload'**.\n\nModel is loaded from configured folder.\n\nInference image and add result to output message. \n\nCalculates approximation of length in centimeters of detected object(s) based on given **image_width_cm**. \n\nParameter **image_width_cm** can be set in 'settings.js'-file separately for each msg.topic (datasource id).\n\nFor example:\n\n`process.env.image_width_cm = JSON.stringify({\"10\":130,\"11\":130,\"20\":130,\"21\":130});`\n\n`{\n    { msg.topic:image width [cm] },\n    { msg.topic:image width [cm] }\n}`\n\n\nBasic image info and exif is added to output message, if available.\n\nTo train a model, please look:\n\nhttps://github.com/juhaautioniemi/tequ-tf2-ca-training-pipeline\n","category":"Tequ-API Client","in":[{"x":100,"y":100,"wires":[{"id":"feaddfb1e7b83060"}]}],"out":[{"x":1020,"y":180,"wires":[{"id":"af7ab0534150089f","port":0}]},{"x":1020,"y":300,"wires":[{"id":"af7ab0534150089f","port":1}]},{"x":1020,"y":380,"wires":[{"id":"af7ab0534150089f","port":2}]}],"env":[{"name":"model_folder","type":"str","value":"savedmodel","ui":{"type":"input","opts":{"types":["str","env"]}}},{"name":"threshold","type":"num","value":"0.75","ui":{"type":"spinner","opts":{"min":0,"max":1}}},{"name":"image_width_cm","type":"env","value":"image_width_cm","ui":{"type":"input","opts":{"types":["env"]}}}],"meta":{"module":"node-red-tequ-ai-detect-sm","version":"0.0.1","author":"juha.autioniemi@lapinamk.fi","desc":"Run prediction on input image using TF2 Savedmodel.","license":"MIT"},"color":"#FFCC66","inputLabels":["msg.payload (image buffer)"],"outputLabels":["result","metagraph","tensorflow info"],"icon":"node-red/status.svg","status":{"x":1020,"y":240,"wires":[{"id":"450407a5f0871af6","port":0}]}},{"id":"af7ab0534150089f","type":"function","z":"1261d76017c1af2f","name":"Predict saved model","func":"const savedmodel = context.get(\"savedmodel\")\nconst imageBuffer = msg.payload;\nlet results = [];\nconst labels = context.get(\"labels\");\nconst threshold = msg.threshold;\nconst image_width = msg.width;\nconst image_height = msg.height;\n\nfunction detect(input){\n    return tf.tidy(() => {\n        const inputTensor = tf.node.decodeImage(input, 3).expandDims(0);  \n        const outputTensor =  savedmodel.predict({input_tensor:inputTensor});\n        const scores = outputTensor['detection_scores'].arraySync();\n        const boxes = outputTensor['detection_boxes'].arraySync();\n        const names = outputTensor['detection_classes'].arraySync();\n        \n        for (let i = 0; i < scores[0].length; i++) {\n            if (scores[0][i] > threshold) {\n                newObject = {\n                    \"bbox\":[\n                        boxes[0][i][1] * image_width,\n                        boxes[0][i][0] * image_height,\n                        (boxes[0][i][3] - boxes[0][i][1]) * image_width,\n                        (boxes[0][i][2] - boxes[0][i][0]) * image_height\n                        ],\n                    \"class\":labels[names[0][i]-1],\n                    \"label\":labels[names[0][i]-1],\n                    \"score\":scores[0][i],\n                    \"length_cm\":NaN\n                }\n                results.push(newObject)\n            }\n        }\n        \n        //Calculate object width if image_width_cm is given input message\n        if(\"image_width_cm\" in msg){\n            const image_width_cm = msg.image_width_cm;    \n            for(let j=0;j<results.length;j++){\n                px_in_cm = image_width_cm / msg.width\n                object_size_cm = px_in_cm * results[j].bbox[2]\n                results[j].length_cm = Math.round(object_size_cm)\n            }\n        }\n        \n        // Create output message\n        let result_message = {\n            \"labels\":context.get(\"labels\"),\n            \"thresholdType\":msg.thresholdType,\n            \"threshold\": msg.threshold,\n            \"image_width_cm\":msg.image_width_cm,\n            \"image_width_cm_type\":msg.image_width_cm_type,\n            \"topic\":msg.topic,\n            \"payload\":{\n                \"inference\":{\n                    \"metadata\":context.get(\"metadata\"),\n                    \"time_ms\": new Date().getTime() - msg.start,\n                    \"validated\":false,\n                    \"result\":results,\n                    \"type\":\"object detection\"\n                },\n                \"image\":{\n                    \"buffer\":imageBuffer,\n                    \"width\": msg.width,\n                    \"height\": msg.height,\n                    \"type\": msg.type,\n                    \"size\": (imageBuffer).length,\n                    \"exif\":{}\n                }\n            }\n        }\n\n        // Add exif information\n        if(msg.exif){\n             result_message.payload.image.exif = msg.exif\n        }\n        \n        node.status({fill:\"blue\",shape:\"dot\",text:(result_message.payload.inference.result).length+\" object(s) found in \"+ result_message.payload.inference.time_ms+\" ms\"});  \n        return result_message;\n    });\n}\n\nreturn [ detect(msg.payload), null, { payload:tf.memory() } ];","outputs":3,"noerr":0,"initialize":"// Code added here will be run once\n// whenever the node is started.\n// Code added here will be run once\n// whenever the node is started.\nconst platform = os.platform()\n\nasync function loadModel(model_path){\n    loaded_model = await tf.node.loadSavedModel(model_path);\n    context.set(\"savedmodel\", loaded_model);\n}\n\nasync function loadMetaGraphs(model_path){\n    const metagraphs = await tf.node.getMetaGraphsFromSavedModel(model_path);\n    context.set(\"metagraphs\", metagraphs);\n    node.send([null,{payload:metagraphs},null]);\n}\n\nasync function warmUpModel(model){\n    tf.tidy(() => {\n        const tempTensor = tf.zeros([1, 2, 2, 3]).toInt();\n        model.predict(tempTensor)\n    });    \n}\n\nif(platform == \"win32\"){\n    model_folder = env.get(\"model_folder\")\n    model_file = model_folder+\"\\\\saved_model.pb\"\n    labels_file = model_folder+\"\\\\labels.json\"\n    metadata_file = model_folder+\"\\\\metadata.json\"\n}\nelse{\n    model_folder = env.get(\"model_folder\")\n    model_file = model_folder+\"/saved_model.pb\"\n    labels_file = model_folder+\"/labels.json\"\n    metadata_file = model_folder+\"/metadata.json\"    \n}\n\nif (context.get(\"labels\") === undefined) {\n    try {\n        context.set(\"labels\",JSON.parse(fs.readFileSync(labels_file, 'utf8')))\n    } catch (err) {\n        node.error(\"Error reading labels\",err)\n    }\n}\n\nif (context.get(\"metadata\") === undefined) {\n    try {\n        context.set(\"metadata\",JSON.parse(fs.readFileSync(metadata_file, 'utf8')))\n    } catch (err) {\n        node.error(\"Error reading metadata\",err)\n    }\n}\n\ntry {\n        if(fs.existsSync(model_folder)){\n            if(fs.existsSync(model_file)){\n                    node.status({fill:\"yellow\",shape:\"dot\",text:\"Loading savedmodel...\"});\n                    await loadModel(model_folder);\n                    node.status({fill:\"yellow\",shape:\"dot\",text:\"Loading metagraphs...\"});\n                    await loadMetaGraphs(model_folder)\n                    node.status({fill:\"yellow\",shape:\"dot\",text:\"Warming up savedmodel...\"});\n                    await warmUpModel(context.get(\"savedmodel\")) \n                    const backend = tf.getBackend()\n                    node.send([null,null,{payload:tf.memory()}]);\n                    node.status({fill:\"green\",shape:\"dot\",text:\"OS: \"+platform+\" | Backend: \"+backend})    \n            }\n            else{\n                node.status({fill:\"red\",shape:\"dot\",text:\"saved_model.pb not found\"})    \n            }\n        }\n        else{\n            node.status({fill:\"red\",shape:\"dot\",text:\"Model folder \"+model_folder+\" not found\"})\n        }\n}\ncatch (err) {\n        node.status({fill:\"red\",shape:\"dot\",text:\"Error loading model\"})\n        node.error(err,err)\n}","finalize":"// Code added here will be run when the\n// node is being stopped or re-deployed.\nconst model = context.get(\"savedmodel\")\ntf.dispose(model)\ncontext.set(\"model\", undefined)\ncontext.set(\"modelInfo\", undefined)","libs":[{"var":"fs","module":"fs"},{"var":"os","module":"os"},{"var":"tf","module":"@tensorflow/tfjs-node-gpu"}],"x":820,"y":180,"wires":[[],[],[]]},{"id":"8e1749840033978f","type":"function","z":"1261d76017c1af2f","name":"Set threshold & image_width_cm","func":"//Define threshold\nlet threshold = 0;\nconst global_settings = global.get(\"settings\") || undefined\nlet thresholdType = \"\"\n\nif(global_settings !== undefined){\n    if(\"threshold\" in global_settings){\n        threshold = global_settings[\"threshold\"]\n        thresholdType = \"global\";\n    }\n}\n\nelse if(\"threshold\" in msg){\n    threshold = msg.threshold;\n    thresholdType = \"msg\";\n    if(threshold < 0){\n        threshold = 0\n    }\n    else if(threshold > 1){\n        threshold = 1\n    }\n}\n\nelse{\n    try{\n        threshold = env.get(\"threshold\");\n        thresholdType = \"env\";\n    }\n    catch(err){\n        threshold = 0.5\n        thresholdType = \"default\";\n    }\n}\n\n\ntry{\n    image_width_cm_type = \"env\";\n    image_width_cm = JSON.parse(env.get(\"image_width_cm\"))[msg.topic];\n        \n}\ncatch(err){\n    image_width_cm = 130\n    image_width_cm_type = \"default\";\n}\n\n\nif(threshold == undefined){\n    threshold = 0\n}\n\nmsg.thresholdType = thresholdType;\nmsg.threshold = threshold;\nmsg.image_width_cm = image_width_cm;\nmsg.image_width_cm_type = image_width_cm_type;\n//node.status({fill:\"green\",shape:\"dot\",text:\"threshold: \"+threshold+\" | Image width: \"+image_width_cm});\nreturn msg;","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[],"x":780,"y":100,"wires":[["af7ab0534150089f"]]},{"id":"feaddfb1e7b83060","type":"function","z":"1261d76017c1af2f","name":"isBuffer?","func":"let timestamp = new Date().toISOString();\nmsg.start = new Date().getTime()\n\nif(Buffer.isBuffer(msg.payload)){\n    //node.status({fill:\"green\",shape:\"dot\",text:timestamp + \" OK\"});  \n    return msg;\n}\nelse{\n    node.error(\"msg.payload is not an image buffer\",msg)\n    node.status({fill:\"red\",shape:\"dot\",text:timestamp + \" msg.payload is not an image buffer\"});  \n    return null;\n}","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[],"x":220,"y":100,"wires":[["f8ca9de56442bbb6"]]},{"id":"450407a5f0871af6","type":"status","z":"1261d76017c1af2f","name":"","scope":["af7ab0534150089f","feaddfb1e7b83060"],"x":860,"y":240,"wires":[[]]},{"id":"ac2317efbd74fb7e","type":"exif","z":"1261d76017c1af2f","name":"","mode":"normal","property":"payload","x":550,"y":100,"wires":[["8e1749840033978f"]]},{"id":"f8ca9de56442bbb6","type":"image-info","z":"1261d76017c1af2f","name":"","x":390,"y":100,"wires":[["ac2317efbd74fb7e"]]},{"id":"e34c898d0c77c799","type":"subflow:1261d76017c1af2f","z":"5a695055.435eb","name":"","env":[],"x":760,"y":680,"wires":[[],[],[]]}]
